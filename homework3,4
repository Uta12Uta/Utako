import sys

# Implement a data structure that stores the most recently accessed N pages.
# See the below test cases to see how it should work.
#
# Note: Please do not use a library like collections.OrderedDict). The goal is
#       to implement the data structure yourself!

def calculate_hash(key):
    assert type(key) == str
    hash = 0
    for i in key:
     hash += ord(i)
    return hash

class Node:
    def __init__(self, key, value):
        self.key = key
        self.value = value
        self.next = None    
        self.pre = None         
        self.url_next = None      


class Cache:
    # Initialize the cache.
    # |n|: The size of the cache.
    def __init__(self, n):
        self.count = 0
        self.size = n
        self.head = None
        self.tail = None
        self.pre = None
        self.next = None
        self.bucket_size = n*2
        self.buckets = [None] * self.bucket_size

    # Access a page and update the cache so that it stores the most recently
    # accessed N pages. This needs to be done with mostly O(1).
    # |url|: The accessed URL
    # |contents|: The contents of the URL
    def remove_from_bucket(self, url):
      bucket_index = calculate_hash(url) % self.bucket_size
      node = self.buckets[bucket_index]
      pre = None
      while node:
          if node.key == url:
              if pre:
                pre.next = node.next
              else:
                self.buckets[bucket_index] = node.next
              return
          pre = node
          node = node.next
    
    def add_to_tail(self,node):   
       node.pre = self.tail
       node.url_next = None
       if self.tail:
           self.tail.url_next = node
       self.tail = node
       if not self.head:
           self.head = node

    def remove_url(self,node):
       if node.pre:
           node.pre.url_next = node.url_next
       else:
           self.head = node.url_next
       if node.url_next:
           node.url_next.pre = node.pre
       else:
           self.tail = node.pre
       node.pre = None
       node.url_next = None


    def access_page(self, url, contents):
        assert type(url) == str
        assert type(contents) == str
        bucket_index = calculate_hash(url) % self.bucket_size
        item = self.buckets[bucket_index]
        found = None
        while item:
          if item.key == url:
            found = item
            break
          item = item.next

        if found:
            found.value = contents
            self.remove_url(found)
            self.add_to_tail(found)
        else:
           found = Node(url, contents)
           found.next = self.buckets[bucket_index]
           self.buckets[bucket_index] = found
           self.add_to_tail(found)
           self.count += 1

        if self.count > self.size:
            oldest = self.head
            self.remove_url(oldest)
            self.remove_from_bucket(oldest.key)
            self.count -= 1

   
    # Return the URLs stored in the cache. The URLs are ordered in the order
    # in which the URLs are mostly recently accessed.
    def get_pages(self):
        result = []
        node = self.tail
        while node:
            result.append(node.key)
            node = node.pre
        return result 


  


def cache_test():
    # Set the size of the cache to 4.
    cache = Cache(4)

    # Initially, no page is cached.
    assert cache.get_pages() == []

    # Access "a.com".
    cache.access_page("a.com", "AAA")
    # "a.com" is cached.

    assert cache.get_pages() == ["a.com"]

    # Access "b.com".
    cache.access_page("b.com", "BBB")
    # The cache is updated to:
    #   (most recently accessed)<-- "b.com", "a.com" -->(least recently accessed)
    assert cache.get_pages() == ["b.com", "a.com"]

    # Access "c.com".
    cache.access_page("c.com", "CCC")
    # The cache is updated to:
    #   (most recently accessed)<-- "c.com", "b.com", "a.com" -->(least recently accessed)
    assert cache.get_pages() == ["c.com", "b.com", "a.com"]

    # Access "d.com".
    cache.access_page("d.com", "DDD")
    # The cache is updated to:
    #   (most recently accessed)<-- "d.com", "c.com", "b.com", "a.com" -->(least recently accessed)
    assert cache.get_pages() == ["d.com", "c.com", "b.com", "a.com"]

    # Access "d.com" again.
    cache.access_page("d.com", "DDD")
    # The cache is updated to:
    #   (most recently accessed)<-- "d.com", "c.com", "b.com", "a.com" -->(least recently accessed)
    assert cache.get_pages() == ["d.com", "c.com", "b.com", "a.com"]

    # Access "a.com" again.
    cache.access_page("a.com", "AAA")
    # The cache is updated to:
    #   (most recently accessed)<-- "a.com", "d.com", "c.com", "b.com" -->(least recently accessed)
    assert cache.get_pages() == ["a.com", "d.com", "c.com", "b.com"]

    cache.access_page("c.com", "CCC")
    assert cache.get_pages() == ["c.com", "a.com", "d.com", "b.com"]
    cache.access_page("a.com", "AAA")
    assert cache.get_pages() == ["a.com", "c.com", "d.com", "b.com"]
    cache.access_page("a.com", "AAA")
    assert cache.get_pages() == ["a.com", "c.com", "d.com", "b.com"]

    # Access "e.com".
    cache.access_page("e.com", "EEE")
    # The cache is full, so we need to remove the least recently accessed page "b.com".
    # The cache is updated to:
    #   (most recently accessed)<-- "e.com", "a.com", "c.com", "d.com" -->(least recently accessed)
    assert cache.get_pages() == ["e.com", "a.com", "c.com", "d.com"]

    # Access "f.com".
    cache.access_page("f.com", "FFF")
    # The cache is full, so we need to remove the least recently accessed page "c.com".
    # The cache is updated to:
    #   (most recently accessed)<-- "f.com", "e.com", "a.com", "c.com" -->(least recently accessed)
    assert cache.get_pages() == ["f.com", "e.com", "a.com", "c.com"]

    # Access "e.com".
    cache.access_page("e.com", "EEE")
    # The cache is updated to:
    #   (most recently accessed)<-- "e.com", "f.com", "a.com", "c.com" -->(least recently accessed)
    assert cache.get_pages() == ["e.com", "f.com", "a.com", "c.com"]

    # Access "a.com".
    cache.access_page("a.com", "AAA")
    # The cache is updated to:
    #   (most recently accessed)<-- "a.com", "e.com", "f.com", "c.com" -->(least recently accessed)
    assert cache.get_pages() == ["a.com", "e.com", "f.com", "c.com"]

    print("Tests passed!")


if __name__ == "__main__":
    cache_test()
